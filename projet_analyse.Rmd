---
title: "Projet Analyse de données MAIN4 2023"
output:
  word_document: default
  html_document: default
  pdf_document: default
date: "2023-04-11"
authors : "Amaury Rodriguez & Camille Hascoët"
---

  Le jeu de donnée que nous souhaitons analyser provient du site kaggle. Il est composé de 41
variables (38 quantitatives et 3 qualitatives). Le dataset représente les données de connexion à
un réseau informatique et comporte des informations telles que le type de connexion ou sa durée par exemple. On va ici s'intéresser à la variable "class" qui nous informe si la connexion est malveillante ou non.

  En effet, de nos jours il y a de plus en plus de cyber-attaques et donc de problèmes liés à la cyber-sécurité. Il devient très important de pouvoir étudier les diverses connexions et déterminer leur nature. Ce projet aura pour but de prédire la variable class, et nous étudierons les résultats obtenus afin de savoir si il est possible de déterminer la nature d'une connexion avec une assez bonne précision pour que l'analyse de données puisse être un outil utile dans ce domaine.
```{r}
library("pROC")
library("MASS")
library(rpart)
library(rpart.plot)
library("randomForest")
library(ggplot2)
library(FactoMineR)

```


## Importation & aperçu des données

```{r}
data <- read.csv("data/Train_data.csv")
head(data)
str(data)
```

## Préparation du dataset

Dans un premier temps nous transformons les variables qualitatives en facteurs pour pouvoir les utiliser dans nos modèles à l'aide de la commande as.factor() de R. De plus, nous vérifions qu'il n'y ait pas de doublons.

```{r}
data$class<-as.factor(data$class)
data$protocol_type<-as.factor(data$protocol_type)
data$flag<-as.factor(data$flag)
data$service<-as.factor(data$service)

doublons <- duplicated(data)
(sum(doublons))
```

Nous avons deux variables constantes (num_outbound_cmds & is_host_login) donc nous pourrons les enlever par la suite. De plus les variables land & num_shells sont quasiment constantes aussi donc nous les enleverons aussi.

```{r}
print("land : ")
table(data$land) #refere to if the connection comes from the intranet
table(data$class[data$land == 1])

print("num_shells :")
table(data$num_shells)
table(data$class[data$num_shells == 1])

print("num_outbound_cmds & is_host_login :")
table(data$num_outbound_cmds)
table(data$is_host_login)

library(dplyr)
```
Nous utilisons donc la commande subset() pour les retirer.

```{r}
data <- subset(data, select = -land)
data <- subset(data, select = -num_outbound_cmds)
data <- subset(data, select = -is_host_login)
data <- subset(data, select = -num_shells)
```
Maintenant, comme la variable qualitative "service" a 66 catégories et que le modèle Random Forest en supporte seulement 53, nous transformons cette variable numériquement pour pallier à ce problème.
```{r}
length(unique(data$service))

data$service <- as.numeric(factor(data$service))
```

## Analyse descriptive

Dans cette section, nous allons faire l'analyse descriptive du jeu de données. On commence par visualiser le nombre de connexions malveillantes à l'aide des commandes ci-dessous.

```{r}
mytable <- table(data[,"class"])
prop_table <- prop.table(mytable)
label_percentages <- paste(names(prop_table), round(prop_table * 100, 1), "%", sep = " ")
pie(mytable, labels = label_percentages, col = c("red","green"))
```
### Les FLAG de statut de connection

```{r}
p1 <-ggplot(data) + aes(x=flag)+geom_bar(aes(fill=flag)) + labs(title = "Distribution des flags de connection")
p1


table(data$flag, data$class)

chisq.test(data$class, data$flag)
```

### Le type de protocole

Nous pouvons observer que la majorité des protocoles utilisés sont des tcp et en monorité des icmp et des udp. D'après le test de Fisher, Nous rejetons H0 et pouvons considérer que le type de protocole a un influence sur si la connection est normal ou non. En effet, les différents protocoles de connection ont des normes de sécurité différentes. UDP n'a pas de check de sécurité intégre.

```{r}
p1 <-ggplot(data) + aes(x=protocol_type)+geom_bar(aes(fill=protocol_type)) + labs(title = "Distribution du type de protocole utilisé pour la connexion")
p1

chisq.test(data$protocol_type,data$class)
table(data$protocol_type, data$class)


```


Nous séparons le dataset en 2 afin d'avoir une données de test après l'entrainement de nos modèles pour interpréter les résultats.

```{r}
set.seed(5678)
perm <- sample(4601,3000)
app <- data[perm,]
valid <- data[-perm,]
```
Ensuite, nous refaisons appel à la fonction as.factor() pour les mêmes raisons que précedemment et en plus nous transformons la variable class en 0 & 1 car certaines méthodes liées aux différentes classifications requièrent des données numérique (1 sera pour les connexions normales et 0 les malveillantes).
```{r}
app2<-app
valid2 <- valid
app2$service<-as.factor(app2$service)
valid2$service<-as.factor(valid2$service)

app2$class <- ifelse(app2$class == "normal", 1, 0)
valid2$class <- ifelse(valid2$class == "normal", 1, 0)
```




# PCA 




#Classification non supervisée

Notre première approche sera la classification non supervisée.

Tout d'abord, les variables du dataset on des unités différentes donc nous devons centrer et réduire les données afin de ne pas créer d'écarts de poids inter-variables.

```{r}

set.seed(1)
app2.cr <- scale(app[,c(1,3,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37)],center = TRUE, scale = TRUE)
```
## K-means

Pour effectuer la méthode des k-means, nous précisons que nous voulons 2 classes car nous cherchons à déterminer si la connexion est malveillante ou non.
```{r}
kmean.result <- kmeans(app2.cr, centers = 2, nstart = 1000)
app.kmean <- cbind.data.frame(app2.cr,classe=factor(kmean.result$cluster))

catdes(app.kmean, num.var = 36)
kmean.table <- table(app2$class,kmean.result$cluster)
kmean.table
kmean.accuracy <- (kmean.table[1,2]+kmean.table[2,1])/3000
kmean.accuracy
```

Nous pouvons voir que ce qui caractérise le plus les connexions normales sont des same_srv_rate et dst_host_same_srv_rate élevés alors que ce qui caractérise le plus les connexions malveillantes sont serror_rate, dst_host_srv_serror_rate et srv_serror_rate élevé ce qui paraît logique car un niveau d'erreur élevé du serveur client et host élevé sont souvent associés à un problème.

##CAH

Ici, nous implémenterons une classification non supervisée à l'aide du CAH (Variante des K-means utilisant une autre méthode pour creer ses clusters). Nous utiliserons la distance de Ward et encore une fois nous préciserons que nous voulons 2 clusters.

```{r}
d.app2.cr <- dist(app2.cr)
cah.ward <- hclust(d.app2.cr, method = "ward.D2")
plot(cah.ward, hang =-1,main="ward.D2",labels=1:nrow(app2)) 
K <- 2
rect.hclust(cah.ward,K)
groups.cah <- cutree(cah.ward, K)
cah.table <- table(app2$class,groups.cah)
cah.table
cah.accuracy <- 1 - (cah.table[1,1]+cah.table[2,2])/3000
cah.accuracy


```


# Classification supervisé


# a) Regression logistique 

La régression logistique a pour but d'expliquer et de prédire les valeurs d'une variable qualitative (ici binaire), à partir de variables explicatives qualitatives et quantitatives


```{r}
#logit_complet <- glm(class~., data=app2, family=binomial)

#logit_step <- step(logit_complet, direction = "backward")


```









# b) LDA

```{r}

model.lda <- lda(class~.,data=app ) 

plot(model.lda)

#prediction
pred_lda <- predict(model.lda,newdata=valid)$class

#accuracy
accuracy.lda = mean(pred_lda==valid$class)
accuracy.lda

# aire sous courbe ROC

pred_numeric_lda <- predict(model.lda,newdata=valid)$posterior[,2]
auc.lda <- roc(valid$class, pred_numeric_lda)$auc
roc.lda <- roc(valid$class, pred_numeric_lda)
auc.lda
```





# c) Arbre Optimal

```{r}

set.seed(1)
arbre <- rpart(class~. ,app,control=rpart.control(minsplit=5,cp=0))
printcp(arbre)
plotcp(arbre)

cp.opt <- arbre$cptable[which.min(arbre$cptable[, "xerror"]), "CP"] 
arbre.opt <- prune(arbre,cp.opt) 
rpart.plot(arbre.opt, type=4)

# prediction
pred_arbre <- predict(arbre.opt,newdata=valid, type="class")

#accuracy 
accuracy.arbre = mean(pred_arbre==valid$class)
accuracy.arbre

## aire sous courbe ROC


pred_numeric <- predict(arbre.opt,newdata=valid)[,2]
roc.aopt <- roc(valid$class, pred_numeric)
roc.aopt


```



# d) random forest

```{r}

set.seed(1234)
model.rf <- randomForest(class~.,data=app)
model.rf
plot(model.rf)
tail(model.rf$err.rate)

## Prediction

pred_forest <- predict(model.rf,newdata=valid, type="class")
table(pred_forest,valid$class)

## Accuracy

accuracy.rf = mean(pred_forest==valid$class)
accuracy.rf


## validation


pred_numeric <- predict(model.rf, valid, type="prob")[,2]
roc.rf <- roc(valid$class, pred_numeric)
roc.rf

var.imp<-model.rf$importance
ord <- order(var.imp,decreasing = TRUE)
barplot(sort(var.imp,decreasing = TRUE)[1:12], names.arg=rownames(var.imp)[ord][1:12],cex.names=0.6, las=2)

var.imp <- as.data.frame(var.imp)
var.imp.df <- cbind(variables = rownames(var.imp),var.imp)
var.imp.df <- var.imp[order(var.imp$MeanDecreaseGini, decreasing = TRUE),]
rownames(var.imp.df) <- NULL
```

### src_bytes 	number of data bytes from source to destination 

### "dst_bytes" typically refers to the number of bytes in the payload of a network packet received by the destination (receiver). It is a field or attribute commonly used in network traffic analysis and monitoring.







# e) gradient boosting



```{r}
library(gbm)
mod.ada<-gbm(class~., data=app2, distribution="adaboost", shrinkage=0.01,n.trees=3000,cv.folds = 5)


print(mod.ada)

prev.ada <- predict(mod.ada,newdata=valid,type = "response")
prev.ada <- round(prev.ada)
prev.ada
accuracy.ada = mean(prev.ada==valid2$class)
accuracy.ada

roc.ada <- roc(valid2$class, prev.ada)
roc.ada


summary(mod.ada)[1:10,]

```

```{r}
valid2$class
```



# f) regression Logistique

Retirer toutes les variables quantitatives


```{r}
library(glmnet)
res_Lasso <- glmnet(as.matrix(app2[,c(-38,-2,-3,-4)]),app2$class,family = 'binomial')
plot(res_Lasso , label = TRUE)
plot(res_Lasso, xvar = "lambda", label = TRUE)
cvLasso <- cv.glmnet(as.matrix(app2[,c(-38,-2,-3,-4)]),app2$class,family="binomial",
type.measure = "class")
cvLasso$lambda.min
plot(cvLasso)
class_logit_lasso=predict(cvLasso, newx = as.matrix(valid2[,c(-38,-2,-3,-4)]), s = 'lambda.min', type = "class")

roc.lasso <- roc(valid2$class, as.numeric(class_logit_lasso))
roc.lasso

accuracy_logit_lasso = mean(class_logit_lasso == valid2$class)  
accuracy_logit_lasso

```




# Comparaison


```{r}
result=matrix(NA, ncol=5, nrow=2)
rownames(result)=c('accuracy', 'AUC')
colnames(result)=c('lda','arbre optimal','random forest','adaboost','lasso')
result[1,]= c(accuracy.lda, accuracy.arbre, accuracy.rf, accuracy.ada,accuracy_logit_lasso)
result[2,]= c(roc.lda$auc,roc.aopt$auc, roc.rf$auc, roc.ada$auc, roc.lasso$auc )
result
```


```{r}
plot(roc.lda,xlim=c(1,0))
plot(roc.aopt, add=TRUE, col=2)
plot(roc.rf, add=TRUE, col=3)
plot(roc.ada, add=TRUE, col=4)
plot(roc.lasso,add=TRUE, col=5)
legend('bottom', col=1:5, paste(c('lda','arbre optimal','random forest','adaboost','lasso')),lwd=1)

```

# ACP

Nous observons un saut après la 2eme dimension, nous allons donc choisir 2 axes. Les 2 premiers axes expliquent 35.153% de l'inertie totale.



```{r}
res.pca <- PCA(app[,-38], quali.sup = c(2,3,4))
barplot(res.pca$eig[,2],names=paste("Dim",1:nrow(res.pca$eig)))
summary(res.pca, ncp=2)
dimdesc(res.pca, proba = 0.2)

```

```{r}
library(factoextra)
var <- get_pca_var(res.pca)
```


```{r}
library("corrplot")
corr.acp <- corrplot(var$cos2, is.corr=FALSE)
```



```{r}
fviz_pca_ind (res.pca,col.ind = app$class)
```

Nous observons que les connections anormals ont des valeurs plus élevées sur l'axe 1 et 2 . L'axe 1 est fortement corrélé à dst_host_srv_error_rate et host_srv_rerror_rate les connections anormales ont un taux plus élevé d'erreur des serveurs ce qui paraît fidèle à la réalite. De même pour l'axe 2 qui est fortement corrélé à reeror_rate et srv_rerror_rate.

```{r}
m <- cor(data[,c(-2,-3,-4,-38)])
corrplot(m)
```

```{r}
library(lares)

corr_cross(data[,c(-2,-3,-4,-38)], # name of dataset
  max_pvalue = 0.05, # display only significant correlations (at 5% level)
  top = 20 # display top 10 couples of variables (by correlation coefficient)
)
```

